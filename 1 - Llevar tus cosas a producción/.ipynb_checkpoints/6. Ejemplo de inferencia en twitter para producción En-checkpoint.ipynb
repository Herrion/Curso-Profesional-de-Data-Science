{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Ejemplo de inferencia en twitter para producción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ping-data.gif](../assets/ping-data.gif)\n",
    "    <sub>Data que genera un ping de una botnet a traves de todo el mundo.</sub>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moving Our Twitter Inference Towards Production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://assets.bwbx.io/images/users/iqjWHBFdfxIU/inIpLScj8Lco/v1/-1x-1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Question:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the probability that a tweet originating from within Colombia contains at least 1 occurence of the word \"yo\" with any given composition of accents, and capital and lowercase letters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tweepy in c:\\users\\willa\\anaconda3\\lib\\site-packages\n",
      "Requirement already satisfied: requests-oauthlib>=0.4.1 in c:\\users\\willa\\anaconda3\\lib\\site-packages (from tweepy)\n",
      "Requirement already satisfied: six>=1.7.3 in c:\\users\\willa\\anaconda3\\lib\\site-packages (from tweepy)\n",
      "Requirement already satisfied: requests>=2.4.3 in c:\\users\\willa\\anaconda3\\lib\\site-packages (from tweepy)\n",
      "Requirement already satisfied: oauthlib>=0.6.2 in c:\\users\\willa\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.4.1->tweepy)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\willa\\anaconda3\\lib\\site-packages (from requests>=2.4.3->tweepy)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in c:\\users\\willa\\anaconda3\\lib\\site-packages (from requests>=2.4.3->tweepy)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in c:\\users\\willa\\anaconda3\\lib\\site-packages (from requests>=2.4.3->tweepy)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\willa\\anaconda3\\lib\\site-packages (from requests>=2.4.3->tweepy)\n",
      "Tweepy version 3.5.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "!pip install tweepy\n",
    "import tweepy\n",
    "from tweepy import Stream\n",
    "print(\"Tweepy version {}\".format(tweepy.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CONSUMER_KEY = \"5Fk4fZDkTGuEGLvzQ3GBe3UEE\"\n",
    "CONSUMER_SECRET = \"PudttRS8xOWzb6UqSuQKkAuQMVxG13qcdF9yOdd9NAVUkrXKta\"\n",
    "ACCESS_TOKEN = \"521880142-52Qf9raiVKFVAmUy7kv89kNCaD27aD8giA1Ungsc\"\n",
    "ACCESS_TOKEN_SECRET = \"VakaTTkNIWl6XYoRimPwRjCmRkuuGz0UWKA3pdgcddKfG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "COLOMBIA_GEO_LOCATION_BOUNDING_BOX = [-78.31, 0.44, -70.71, 11.39]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the Twitter API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define some cleaning functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unidecode\n",
      "  Downloading Unidecode-0.04.21-py2.py3-none-any.whl (228kB)\n",
      "Installing collected packages: unidecode\n",
      "Successfully installed unidecode-0.4.21\n"
     ]
    }
   ],
   "source": [
    "!pip install unidecode\n",
    "from unidecode import unidecode\n",
    "\n",
    "\n",
    "def make_lowercase(tweet):\n",
    "    return tweet.lower()\n",
    "\n",
    "\n",
    "def remove_diacritics(tweet):\n",
    "    return unidecode(tweet)\n",
    "\n",
    "\n",
    "def remove_non_alpha_characters(tweet):\n",
    "    return ''.join(character for character in tweet if character.isalpha() or character == ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a stream listener"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATABASE_NAME = 'twitter_inference'\n",
    "TABLE_NAME = 'tweets'\n",
    "USER = 'postgres'\n",
    "HOST = 'localhost'\n",
    "PASSWORD = 'marckzucaritas1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting psycopg2\n",
      "  Downloading psycopg2-2.7.3.2-cp36-cp36m-win_amd64.whl (993kB)\n",
      "Installing collected packages: psycopg2\n",
      "Successfully installed psycopg2-2.7.3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install psycopg2\n",
    "import psycopg2\n",
    "from tweepy import StreamListener\n",
    "\n",
    "\n",
    "class PersistedStreamListener(StreamListener):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._database_connection = psycopg2.connect(dbname=DATABASE_NAME, user=USER, host=HOST, password=PASSWORD)\n",
    "        super().__init__()\n",
    "    \n",
    "    def on_status(self, status):\n",
    "        cleaned_status_text = self._clean_status_text(status.text)\n",
    "        self._insert_status(id_str=status.id_str, text=cleaned_status_text)\n",
    "        \n",
    "    def _clean_status_text(self, status_text):\n",
    "        cleaned_status_text = status_text\n",
    "        for cleaning_function in self._cleaning_functions:\n",
    "            cleaned_status_text = cleaning_function(cleaned_status_text)\n",
    "        return cleaned_status_text\n",
    "    \n",
    "    def _insert_status(self, id_str, text):\n",
    "        cursor = self._database_connection.cursor()\n",
    "        insert_statement = \"\"\"INSERT INTO {table_name} VALUES ('{id_str}', '{text}')\"\"\".format(\n",
    "                table_name=TABLE_NAME, id_str=id_str, text=text)\n",
    "\n",
    "        cursor.execute(insert_statement)\n",
    "        self._database_connection.commit()\n",
    "        \n",
    "        cursor.close()\n",
    "        \n",
    "    @property\n",
    "    def _cleaning_functions(self):\n",
    "        return [make_lowercase, remove_diacritics, remove_non_alpha_characters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "streaming_api = Stream(auth=auth, listener=PersistedStreamListener())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beta distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://i.imgur.com/mj059cS.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creando nuestro modelo matematico\n",
    "\n",
    "Vamos a construir un modelo matemático para responder nuestra pregunta original.\n",
    "\n",
    "Lo primero que es importante explicar es una distribución beta, una distribución beta es una distribución de probabilidad canónica usada para mostrar incertidumbre alrededor de cada posible probabilidad, una probabilidad por supuesto siendo un numero entre 0 y 1, siendo la verdadera probabilidad del proceso.\n",
    "\n",
    "Entonces entremos a esto un poco más, de nuevo la pregunta es:\n",
    "\n",
    "¿Cuál es la probabilidad de que un tweet dado en Colombia contenga la palabra “yo”?\n",
    "\n",
    "Entonces la respuesta va a ser un número entre 0 y 1 por definición de lo que es una probabilidad\n",
    "y esta distribución de probabilidad es una distribución beta es efectivamente una tabla de consulta\n",
    "para los datos dados que hemos observado y por supuesto limpiada y persistida, etc.\n",
    "\n",
    "Una distribución beta es una función que toma dos parámetros, el primero es alpha y el segundo beta, entonces para interpretar una distribución beta vemos la altura de la curva y la altura de la curva es proporcional a la probabilidad de dibujar el valor por debajo de él en el eje x.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stream tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "streaming_api.filter(locations=COLOMBIA_GEO_LOCATION_BOUNDING_BOX, async=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import beta as beta_distribution\n",
    "\n",
    "\n",
    "X_VALUES = np.linspace(0, 1, 1002)[1:-1]\n",
    "DATABASE_CONNECTION = psycopg2.connect(dbname=DATABASE_NAME, user=USER, host=HOST, password=PASSWORD)\n",
    "KEYWORD = 'yo'\n",
    "\n",
    "\n",
    "def fetch_tweets(database_connection=DATABASE_CONNECTION):\n",
    "    cursor = database_connection.cursor()\n",
    "    select_statement = \"\"\"SELECT text FROM {table}\"\"\".format(table=TABLE_NAME)\n",
    "    cursor.execute(select_statement)\n",
    "    result = cursor.fetchall()\n",
    "    \n",
    "    return [tweet[0] for tweet in result]\n",
    "\n",
    "\n",
    "def compute_alpha_and_beta(tweets, keyword=KEYWORD):\n",
    "    number_of_occurences = sum(keyword in tweet for tweet in tweets)\n",
    "    alpha = 1 + number_of_occurences\n",
    "    beta = 1 + (len(tweets) - number_of_occurences)\n",
    "    \n",
    "    return alpha, beta\n",
    "\n",
    "\n",
    "def compute_pdf_y_values(alpha, beta, x_values=X_VALUES):\n",
    "    return beta_distribution(alpha, beta).pdf(x_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatización\n",
    "\n",
    "Lo que no estamos haciendo es ejecutando el código de forma manual. Ahora pasaremos a automatizar el proceso, lo cual es sinónimo de llevar nuestras cosas a producción.\n",
    "\n",
    "Crearemos un panel de control, repito, que se refresque solo. Para ello usaremos bokeh\n",
    "\n",
    "Para usar Bokeh lo primero que tenemos que hacer es iniciar un servidor Bokeh. Para hacer eso vamos a ir a nuestra terminal.\n",
    "\n",
    "bokeh serve\n",
    "\n",
    "Lo segundo que vamos a hacer aquí es traer nuestros tweets y luego definir alfa y beta. Recuerden que alfa y beta se definen primero, calculando primero cuántos de estos tweets realmente contienen la palabra clave “yo”, la cual nos interesa. Y continuación alfa se define como uno más el número de ocurrencias positivas. Y beta se define como uno más el número de ocurrencias negativas.\n",
    "\n",
    "Después generamos código para esta figura en sí. De nuevo, todo esto está en la documentación de Bokeh. Creamos este objeto figure. Le damos un título, una etiqueta para el eje x, una etiqueta para el eje y, dimensiones en nuestro cuaderno interactivo.\n",
    "\n",
    "Y finalmente, y esto es digamos que la sustancia aquí, definimos esta función update. Llamamos esta función update cada 50 milisegundos y lo que hace cada 50 milisegundos es:\n",
    "\n",
    " * Trae tweets\n",
    " * Redefine alfa y beta.\n",
    " * Recalcula\n",
    " * Agrega estos nuevos datos a nuestra visualización.\n",
    "\n",
    "Pero por supuesto la idea aquí es automatización, esa es realmente la palabra clave. Que cada vez que queramos ver, ya sabes, cómo se ve esta curva después de observar muchos más datos\n",
    "sólo hay un lugar en el cual buscar. Y lo que no voy a hacer es volver a ejecutar manualmente este análisis. Sólo estoy mirando mi modelo llevado a producción, obteniendo estos resultados y realmente pasando a lo siguiente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bokeh.client import push_session\n",
    "from bokeh.models import FixedTicker\n",
    "from bokeh.plotting import figure, curdoc, reset_output\n",
    "\n",
    "# reset output\n",
    "reset_output()\n",
    "\n",
    "# initialize alpha, beta\n",
    "tweets = fetch_tweets()\n",
    "alpha, beta = compute_alpha_and_beta(tweets=tweets)\n",
    "pdf_y_values = compute_pdf_y_values(alpha, beta)\n",
    "\n",
    "# create bokeh figure\n",
    "bokeh_figure = figure(\n",
    "    title='PDF of True Probability of a Tweet Containing Keyword',\n",
    "    x_axis_label='true_probability',\n",
    "    y_axis_label='probability_density',\n",
    "    width=1000,\n",
    "    height=600\n",
    ")\n",
    "bokeh_figure.xaxis[0].ticker=FixedTicker(ticks=list(np.linspace(0, 1, 21)))\n",
    "bokeh_line = bokeh_figure.line(X_VALUES, pdf_y_values, color=\"navy\", line_width=4)\n",
    "\n",
    "# open a session to keep our local document in sync with server\n",
    "session = push_session(curdoc())\n",
    "\n",
    "def update():\n",
    "    tweets = fetch_tweets()\n",
    "    alpha, beta = compute_alpha_and_beta(tweets=tweets)\n",
    "    pdf_y_values = compute_pdf_y_values(alpha, beta)\n",
    "    bokeh_line.data_source.data.update(y=pdf_y_values)\n",
    "\n",
    "curdoc().add_periodic_callback(update, 50)\n",
    "\n",
    "session.show(bokeh_figure)\n",
    "\n",
    "session.loop_until_closed()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
